{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rev_id  toxicity_score\n",
      "0  2232.0             0.0\n",
      "1  2232.0             0.0\n",
      "2  2232.0             1.0\n",
      "3  2232.0             0.0\n",
      "4  2232.0             1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# in the wiki file we have the data of toxic comments and the corresponding labels, we need to split the data into train and test\n",
    "# we access the data from the wiki file\n",
    "wiki = pd.read_csv('data/wiki/toxicity_annotated_comments.tsv', sep = '\\t')\n",
    "# we access the data from the wiki file\n",
    "wiki_labels = pd.read_csv('data/wiki/toxicity_annotations.tsv', sep = '\\t')\n",
    "\n",
    "\n",
    "# from the wiki_labels we drop the worker id and toxicity column because we only need the rev_id and the toxicity score\n",
    "wiki_labels = wiki_labels.drop(['worker_id', 'toxicity'], axis = 1)\n",
    "\n",
    "# print the first 40 rows of the wiki_labels\n",
    "print(wiki_labels.head(5))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
